{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298af494",
   "metadata": {},
   "source": [
    "# Scraping British Airways Reviews from Skytrax \n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "\n",
    "Understanding customer insights, needs, and feedback is crucial to increase quality of hospitality and service of BA. Here, before performing the analysis, i'll collect data from the third-party, Skytrax, about customer feedback, and gain customer insights about BA's Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be41b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import required libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc325e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways/\"\n",
    "\n",
    "page_size = 300\n",
    "\n",
    "req_delay = 2\n",
    "\n",
    "output_file = \"D:/Create/FORAGE [BA]/ba_reviews_adv.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9f7fb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function to scrape the website\n",
    "\n",
    "## scraping single review article\n",
    "\n",
    "def scrape_single_review(article):\n",
    "    review_data = {}\n",
    "\n",
    "    review_data['title'] = article.find('h2', class_='text_header').get_text(strip=True)\n",
    "\n",
    "    # author info\n",
    "\n",
    "    author_info = article.find('h3', class_='text_sub_header')\n",
    "    review_data['author'] = author_info.find('span', itemprop='name').get_text(strip=True)\n",
    "    review_data['country'] = author_info.find_all(string=True)[3].strip('  ()')\n",
    "    review_data['date'] = article.find('time')['datetime']\n",
    "\n",
    "    # floown verified\n",
    "    verified_tag = article.find('strong')\n",
    "    review_data['verified'] = 'Trip Verified' in verified_tag.get_text() if verified_tag else False\n",
    "\n",
    "    # rating out of 10 \n",
    "    review_data['ratings'] = article.find('span', itemprop='ratingValue').get_text(strip=True)\n",
    "\n",
    "    # review box\n",
    "    review_box = article.find('div', class_='tc_mobile')\n",
    "    review_data['review_text'] = review_box.find_all(string=True)[3] \n",
    "\n",
    "    # table stats\n",
    "    rating_table = article.find('table', class_= \"review-ratings\")\n",
    "    if rating_table:\n",
    "        rows = rating_table.find_all('tr')\n",
    "        for row in rows:\n",
    "            header = row.find('td', class_= \"review-rating-header\")\n",
    "            if header:\n",
    "                # striping the header, so we got clear text\n",
    "                header_text = (header.get_text(strip=True)\n",
    "                               .lower()\n",
    "                               .replace(' ','_')\n",
    "                               .replace('&','and')\n",
    "                               .replace('/','_'))\n",
    "                \n",
    "                value_cell = header.find_next_sibling('td')\n",
    "\n",
    "                # star rating value\n",
    "\n",
    "                if 'stars' in value_cell.get('class', []):\n",
    "                    stars = len(value_cell.find_all('span', class_='star fill'))\n",
    "                    review_data[header_text] = stars\n",
    "                else:\n",
    "                    review_data[header_text] = value_cell.get_text(strip=True)\n",
    "    \n",
    "    return review_data\n",
    "\n",
    "## scraping a page\n",
    "\n",
    "def scrape_page(url):\n",
    "    try:\n",
    "        \n",
    "        response = requests.get(url)\n",
    "\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        reviews = []\n",
    "\n",
    "        review_articles = soup.find_all(\"article\", itemprop=\"review\")\n",
    "\n",
    "        for article in review_articles:\n",
    "            reviews.append(scrape_single_review(article))\n",
    "\n",
    "        return reviews\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"error scraping page {url}: {str()}\")\n",
    "        return[]\n",
    "\n",
    "## scraping multiple page\n",
    "\n",
    "def scrape_multiple_pages(base_url, page_size):\n",
    "    all_reviews = []\n",
    "\n",
    "    for page_num in range(1, page_size + 1):\n",
    "        print(f\"Scraping page {page_num}/{page_size}...\", end='\\r')\n",
    "\n",
    "        if page_num == 1:\n",
    "            page_url = base_url\n",
    "        else:\n",
    "            page_url = f\"{base_url}page/{page_num}/\"\n",
    "\n",
    "        page_reviews = scrape_page(page_url)\n",
    "        all_reviews.extend(page_reviews)\n",
    "\n",
    "        time.sleep(req_delay)\n",
    "    \n",
    "    print(f\"\\nScraped {len(all_reviews)} reviews in total\")\n",
    "    return all_reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4ce864fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to scrape up to 300 pages from https://www.airlinequality.com/airline-reviews/british-airways/\n",
      "Scraping page 300/300...\n",
      "Scraped 3000 reviews in total\n",
      "Scraped 3000 reviews in total\n"
     ]
    }
   ],
   "source": [
    "# main scraping process\n",
    "\n",
    "print(f\"Starting to scrape up to {page_size} pages from {base_url}\")\n",
    "reviews = scrape_multiple_pages(base_url, page_size)\n",
    "print(f\"Scraped {len(reviews)} reviews in total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aa60166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 3000 reviews to D:/Create/FORAGE [BA]/ba_reviews_adv.csv\n"
     ]
    }
   ],
   "source": [
    "# save the data\n",
    "\n",
    "df = pd.DataFrame(reviews)\n",
    "\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Saved {len(df)} reviews to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35faef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
